#!/usr/bin/env python3

import argparse
import copy
import configparser
import datetime
import enum
import os
import sys

import bash_imitation
import exp_lib
import lib


FPATH = os.path.dirname(os.path.realpath(__file__))
LT_EXECUTABLE = os.path.join(FPATH, "lt_driver.py")
DRIVER_EXECUTABLE = os.path.join(FPATH, "driver.py")
LT_GNUPLOT = os.path.join(FPATH, "lt.gp")
DRIVER_GNUPLOT = os.path.join(FPATH, "plot.gp")


class Stage(enum.Enum):

	""" Represents the stages of the pipeline."""

	CREATE_NEW_DIRS = "create_new_dirs"
	METADATA = "metadata"
	LATENCY_THROUGHPUT = "latency_throughput"
	DRIVER = "driver"

	def __str__(self):
		return self.value

	@staticmethod
	def next(stage):
		if stage == Stage.CREATE_NEW_DIRS:
			return Stage.METADATA
		elif stage == Stage.METADATA:
			return Stage.LATENCY_THROUGHPUT
		elif stage == Stage.LATENCY_THROUGHPUT:
			return Stage.DRIVER


def extract_human_tag(config_file):

	""" Reads the human tag from the config file.

	Args:
		config_file (str): .ini file
	
	Returns:
		human tag
	"""

	config = configparser.ConfigParser()
	config.read(config_file)

	return config["DEFAULT"]["LOGS_DIR"]


def generate_testrun_name(suffix):

	""" Creates a test run directory's name in the format
	test_<timestamp>_<suffix>.

	Args:
		suffix (str): human readable tag
	
	Returns:
		generated name.
	"""

	timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
	name = "test_{0}_{1}".format(timestamp, suffix)

	return name


def create_directories(location, suffix):

	""" Creates the run's directories.

	Args:
		suffix (str): appending dir name with a human readable tag.
	
	Returns:
		Name of all created directories
	"""

	overall_dir = bash_imitation.create_dir(location, generate_testrun_name(suffix))
	graph_dir = bash_imitation.create_dir(overall_dir, "graphs")
	raw_out_dir = bash_imitation.create_dir(overall_dir, "raw_out")
	csv_dir = bash_imitation.create_dir(overall_dir, "csv_files")


	return overall_dir, graph_dir, raw_out_dir, csv_dir


def reconstruct_directories(location, existing_directory):

	""" Reconstructs the structure of the existing directory and returns
	the inner directories.

	Args:
		location (str): location of existing directory
		existing_directory (str): name of existing directory

	Return:
		Name of all directories.
	"""

	overall_dir = os.path.join(location, existing_directory)
	graph_dir = os.path.join(overall_dir, "graphs")
	raw_out_dir = os.path.join(overall_dir, "raw_out")
	csv_dir = os.path.join(overall_dir, "csv_files")

	return overall_dir, graph_dir, raw_out_dir, csv_dir


def copy_and_create_metadata(location, config_file):

	""" Copies config file as params.ini, creates a metadata file of
	current git hash.

	Args:
		location (str): location in which all files are copied / created
		config_file (str): config file to be copied.
	
	Return: 
		None.
	"""

	# copy parameter file
	cmd = "cp {0} {1}".format(config_file, os.path.join(location, "params.ini"))
	lib.call(cmd, "could not copy params file.")

	# create git hash file
	with open(os.path.join(location, "git_commit_hash.txt"), "w") as f:
		git_commit_hash = bash_imitation.git_commit_hash()
		f.write("commit_hash: " + git_commit_hash)

		submodule = "vendor"
		git_submodule_hash = bash_imitation.git_submodule_commit_hash(submodule)
		f.write("\nsubmodule_commit_hash: " + git_submodule_hash)


def call_latency_throughput(location, baseline_file, lt_file, params_file, csv_file):

	""" Calls the latency throughput script and plots its csv files.

	Args:
		location (str): absolute path of location directory.
		baseline_file (str): original params config file, abs path
		lt_file (str): latency throughput params config, abs path
		params_file (str): abs path of param output file
		csv_file (str): abs path of csv file
	
	Returns:
		None.
	"""

	# call lt script
	cmd = "{0} {1} {2} {3} {4}".format(
			LT_EXECUTABLE, baseline_file, lt_file, params_file, csv_file)
	lib.call(cmd, "lt_driver script failed")

	# plot its csv
	


def move_logs(baseline_file, dest):

	""" Moves logs generated by a run of the latency throughput script.

	Args:
		baseline_file (str): original params config file, abs path, used to
			construct source log directory.
		dest (str): abs path of new log directory.

	Returns:
		None.
	"""

	# move the generated logs
	src_logs = exp_lib.find_log_dir(FPATH, baseline_file)
	bash_imitation.move_logs(src_logs, dest)


def driver(baseline_file, override_file, csv_dir, csv_file):

	""" Calls driver script."""

	cmd = ("{0} --benchmark --driver_node localhost "
			"--ini_files {1} "
			"--override {2} "
			"--csv_path {3} "
			"--csv_file {4}").format(
				DRIVER_EXECUTABLE, baseline_file, override_file, csv_dir, csv_file)
	lib.call(cmd, "driver script failed")


def main():

	parser = argparse.ArgumentParser(description="coordinator script for pipeline")
	parser.add_argument("config", help=".ini file with config params, params.ini")
	parser.add_argument("lt_config", help=".ini file with latency throughput params")
	parser.add_argument("--start_stage", type=Stage, default=Stage.CREATE_NEW_DIRS, 
			choices=[stage for stage in Stage],
			help="which stage to start running at. Useful for testing.")
	parser.add_argument("--end_stage", type=Stage, default = Stage.DRIVER,
			choices = [stage for stage in Stage],
			help="which stage to stop running after. Useful for testing.")
	parser.add_argument("--existing_directory",
			help="existing directory to use. Useful for testing.")

	args = parser.parse_args()
	args.config = os.path.join(FPATH, args.config) # replace with abs path
	args.lt_config = os.path.join(FPATH, args.lt_config)

	if args.start_stage is not Stage.CREATE_NEW_DIRS and not args.existing_directory:
		print("You must provide an existing test run directory with this stage.")
		parser.print_help()
		return -1

	# Starting pipeline
	stage = args.start_stage
	overall_dir, graph_dir, raw_out_dir, csv_dir = None, None, None, None

	# stage creating new directories
	if stage == Stage.CREATE_NEW_DIRS:
		human_tag = extract_human_tag(args.config)
		overall_dir, graph_dir, raw_out_dir, csv_dir = create_directories(
				os.path.join(FPATH, ".."), human_tag)
		if stage == args.end_stage:
			return 0
		stage = Stage.next(stage)
	else:
		overall_dir, graph_dir, raw_out_dir, csv_dir = reconstruct_directories(
				os.path.join(FPATH, ".."), args.existing_directory)

	# stage metadata
	if stage == Stage.METADATA:
		copy_and_create_metadata(overall_dir, args.config)
		if stage == args.end_stage:
			return 0
		stage = Stage.next(stage)

	# file locations
	override_file = os.path.join(overall_dir, "override.ini")
	lt_csv = os.path.join(csv_dir, "lt.csv")
	lt_logs = os.path.join(raw_out_dir, "lt_logs")
	driver_logs = os.path.join(raw_out_dir, "driver_logs")
	driver_csv = os.path.join(csv_dir, "driver.csv")

	# stage latency throughput
	if stage == stage.LATENCY_THROUGHPUT:

		param_output = override_file
		call_latency_throughput(overall_dir, args.config, args.lt_config,
				param_output, lt_csv)
		move_logs(args.config, lt_logs)
		bash_imitation.gnuplot(LT_GNUPLOT, lt_csv, graph_dir)
	
		if stage == args.end_stage:
			return 0
		stage = Stage.next(stage)

	# stage driver
	if stage == stage.DRIVER:

		# warning: driver script has too many dependencies on the csv_dir
		# and csv_file being separated for me to bother right now. Implicitly
		# assume that the abs path is just the joining of the dir and filename.
		driver(args.config, override_file, csv_dir, "driver.csv")
		move_logs(args.config, driver_logs)
		bash_imitation.gnuplot(DRIVER_GNUPLOT, driver_csv, graph_dir)

	return 0


if __name__ == "__main__":
	sys.exit(main())
